# Image Captioning and Question Answering using BLIP-2 Model

<p align="center">
  <img width="800" src="Chat with AI About Images using Blip2.png" "image">
</p>

##
<br/><br/> 

<font size= "4" >

In this tutorial, we will demonstarte how to use a Visual Language Models named "Blip2" 

We will utilize the BLIP-2 model from Hugging Face to generate captions for an image and answer specific questions about its content. 
The model is first used to describe the image, then queried to answer questions regarding objects and colors in the image. 


<br/>

This tutorial has 2 parts : 

🔍 Install Python Conda enviroment with the relevant Python libraries 

🐍 Python Code that enable to ask question about a custom image 

<br/>

You can find the link for the [tutorial](https://youtu.be/_kuGdmEFiVs) here. 

You can find more cool similar projects and tutorials in this [playlist](https://www.youtube.com/playlist?list=PLdkryDe59y4a2PRJda-Z7M7Sod7uQKT2d)

Enjoy

Eran
<br/><br/> 

</font>

# Recommended courses and relevant products 
<font size= "4" >

A perfect course for learning modern Computer Vision with deep dive in TensorFlow , Keras and Pytorch . You can find it [here](http://bit.ly/3HeDy1V).

Perfect course for every computer vision enthusiastic

Before we continue , I actually recommend this [book](https://amzn.to/3STWZ2N) for deep learning based on Tensorflow and Keras. 



</font>

# Connect

<font size= "4" >
If you have any suggestions about papers, feel free to mail me :)

- [☕ Buy me a coffee](https://ko-fi.com/eranfeit)
- [🌐 My Website](https://eranfeit.net)
- [▶️ Youtube.com/@eranfeit](https://www.youtube.com/channel/UCTiWJJhaH6BviSWKLJUM9sg)
- [🐙 Facebookl](https://www.facebook.com/groups/3080601358933585)
- [🖥️ Email](mailto:feitgemel@gmail.com)
- [🐦 Twitter](https://twitter.com/eran_feit )
- [😸 GitHub](https://github.com/feitgemel)
- [📸 Instagram](https://www.instagram.com/eran_feit/)
- [🤝 Fiverr ](https://www.fiverr.com/s/mB3Pbb)
- [📝 Medium ](https://medium.com/@feitgemel)


</font>

